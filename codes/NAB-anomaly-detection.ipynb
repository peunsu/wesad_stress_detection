{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "def fxn():\n",
    "    warnings.warn(\"deprecated\", DeprecationWarning)\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    fxn()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pylab as plt\n",
    "from matplotlib.pyplot import plot, ion, show, savefig, cla, figure\n",
    "from pathlib import Path\n",
    "\n",
    "from data_loader_pytorch import DataGenerator\n",
    "from models_pytorch import VAEmodel, LSTMModel\n",
    "from trainers_pytorch import VAETrainer\n",
    "from utils import process_config, create_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # keep GPU ordering consistent\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load VAE model\n",
    "config = process_config('config.json')\n",
    "# create the experiments dirs\n",
    "create_dirs([config['result_dir'], config['checkpoint_dir'], config['checkpoint_dir_lstm']])\n",
    "# create your data generator\n",
    "data = DataGenerator(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for VAEmodel:\n\tsize mismatch for enc_conv1.weight: copying a param with shape torch.Size([32, 14, 3, 1]) from checkpoint, the shape in current model is torch.Size([32, 1, 3, 14]).\n\tsize mismatch for enc_conv2.weight: copying a param with shape torch.Size([64, 32, 3, 1]) from checkpoint, the shape in current model is torch.Size([64, 32, 3, 14]).\n\tsize mismatch for enc_conv3.weight: copying a param with shape torch.Size([128, 64, 3, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 3, 14]).\n\tsize mismatch for enc_conv4.weight: copying a param with shape torch.Size([512, 128, 6, 1]) from checkpoint, the shape in current model is torch.Size([512, 128, 6, 14]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo VAE checkpoint found in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcheckpoint_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m latest_checkpoint \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(checkpoint_files, key\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28mint\u001b[39m(x\u001b[38;5;241m.\u001b[39mname\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]))\n\u001b[0;32m---> 11\u001b[0m \u001b[43mvae_trainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlatest_checkpoint\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m vae_model\u001b[38;5;241m.\u001b[39meval()\n",
      "File \u001b[0;32m~/ml_project/codes/trainers_pytorch.py:189\u001b[0m, in \u001b[0;36mVAETrainer.load_model\u001b[0;34m(self, checkpoint_path)\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(checkpoint_path):\n\u001b[1;32m    188\u001b[0m     checkpoint \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(checkpoint_path, map_location\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m--> 189\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel_state_dict\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mload_state_dict(checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moptimizer_state_dict\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m    191\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_losses \u001b[38;5;241m=\u001b[39m checkpoint\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain_losses\u001b[39m\u001b[38;5;124m'\u001b[39m, [])\n",
      "File \u001b[0;32m~/ml_project/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:2624\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2616\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2617\u001b[0m             \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m   2618\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2619\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)\n\u001b[1;32m   2620\u001b[0m             ),\n\u001b[1;32m   2621\u001b[0m         )\n\u001b[1;32m   2623\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2624\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   2625\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2626\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)\n\u001b[1;32m   2627\u001b[0m         )\n\u001b[1;32m   2628\u001b[0m     )\n\u001b[1;32m   2629\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for VAEmodel:\n\tsize mismatch for enc_conv1.weight: copying a param with shape torch.Size([32, 14, 3, 1]) from checkpoint, the shape in current model is torch.Size([32, 1, 3, 14]).\n\tsize mismatch for enc_conv2.weight: copying a param with shape torch.Size([64, 32, 3, 1]) from checkpoint, the shape in current model is torch.Size([64, 32, 3, 14]).\n\tsize mismatch for enc_conv3.weight: copying a param with shape torch.Size([128, 64, 3, 1]) from checkpoint, the shape in current model is torch.Size([128, 64, 3, 14]).\n\tsize mismatch for enc_conv4.weight: copying a param with shape torch.Size([512, 128, 6, 1]) from checkpoint, the shape in current model is torch.Size([512, 128, 6, 14])."
     ]
    }
   ],
   "source": [
    "# create a VAE model and load the latest checkpoint\n",
    "vae_model = VAEmodel(config).to(device)\n",
    "vae_model.eval()\n",
    "vae_trainer = VAETrainer(vae_model, data, config)\n",
    "\n",
    "checkpoint_dir = config['checkpoint_dir']\n",
    "checkpoint_files = [f for f in Path(checkpoint_dir).iterdir() if f.name.startswith('vae_checkpoint') and f.name.endswith('.pth')]\n",
    "if not checkpoint_files:\n",
    "    raise FileNotFoundError(f\"No VAE checkpoint found in {checkpoint_dir}\")\n",
    "latest_checkpoint = max(checkpoint_files, key=lambda x: int(x.name.split('_')[-1].split('.')[0]))\n",
    "vae_trainer.load_model(latest_checkpoint)\n",
    "vae_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load LSTM model\n",
    "lstm_model = LSTMModel(config).to(device)\n",
    "lstm_checkpoint_path = Path(config['checkpoint_dir_lstm']) / 'lstm_model.pth'\n",
    "if not lstm_checkpoint_path.is_file():\n",
    "    raise FileNotFoundError(f\"Expected LSTM checkpoint at {lstm_checkpoint_path}\")\n",
    "lstm_state_dict = torch.load(lstm_checkpoint_path, map_location=device)\n",
    "lstm_model.load_state_dict(lstm_state_dict)\n",
    "lstm_model.eval()\n",
    "print(f\"Loaded LSTM checkpoint: {lstm_checkpoint_path.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The given sequence has 17988 samples\n",
      "(17941, 48, 14)\n",
      "(17413, 12, 48, 14)\n"
     ]
    }
   ],
   "source": [
    "# load normalised time series\n",
    "data_dir = Path('../data/')\n",
    "filename = data_dir / 'test.csv'\n",
    "df = pd.read_csv(filename)\n",
    "\n",
    "result = {}\n",
    "result['test'] = df.drop(columns=['label', 'subject_id'], axis=1).to_numpy()\n",
    "result['idx_anomaly_test'] = df['label'].to_numpy()\n",
    "\n",
    "# slice into rolling windows and rolling sequences\n",
    "def slice_rolling_windows_and_sequences(config, time_seq):\n",
    "    n_sample = len(time_seq)\n",
    "    print(\"The given sequence has {} samples\".format(n_sample))\n",
    "    n_vae_win = n_sample - config['l_win'] + 1\n",
    "    rolling_windows = np.zeros((n_vae_win, config['l_win'], time_seq.shape[1]), dtype=np.float32)\n",
    "    for i in range(n_vae_win):\n",
    "        rolling_windows[i] = time_seq[i:i + config['l_win']]\n",
    "\n",
    "    n_lstm_seq = n_sample - config['l_seq']*config['l_win']+1\n",
    "    lstm_seq = np.zeros((n_lstm_seq, config['l_seq'], config['l_win'], time_seq.shape[1]), dtype=np.float32)\n",
    "    for i in range(n_lstm_seq):\n",
    "        cur_seq = time_seq[i:i+config['l_seq']*config['l_win']]\n",
    "        for j in range(config['l_seq']):\n",
    "            lstm_seq[i,j] = cur_seq[config['l_win']*j:config['l_win']*(j+1)]\n",
    "\n",
    "    return rolling_windows, lstm_seq\n",
    "\n",
    "test_windows, test_seq = slice_rolling_windows_and_sequences(config, result['test'])\n",
    "print(test_windows.shape)\n",
    "print(test_seq.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate ELBO and LSTM prediction error on the validation set\n",
    "# evaluate some anomaly detection metrics\n",
    "def evaluate_vae_anomaly_metrics_for_a_window(test_win):\n",
    "    window_tensor = torch.from_numpy(test_win).float().unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        recon_win, latent_mean, latent_std = vae_model(window_tensor)\n",
    "    recon_win = recon_win.squeeze(0).cpu().numpy()\n",
    "    latent_mean = latent_mean.squeeze(0).cpu().numpy()\n",
    "    latent_std = latent_std.squeeze(0).cpu().numpy()\n",
    "\n",
    "    test_vae_recons_error = np.sum(np.square(recon_win - test_win))\n",
    "    safe_std = np.clip(latent_std, 1e-9, None)\n",
    "    test_vae_kl = 0.5 * (\n",
    "        np.sum(np.square(latent_mean))\n",
    "        + np.sum(np.square(safe_std))\n",
    "        - np.sum(np.log(np.square(safe_std)))\n",
    "        - config['code_size']\n",
    "    )\n",
    "\n",
    "    sigma2 = vae_model.get_sigma2().item()\n",
    "    input_dims = vae_model.input_dims\n",
    "    sigma_regularisor = input_dims / 2.0 * np.log(sigma2) + input_dims * np.pi\n",
    "    test_vae_elbo = test_vae_recons_error / sigma2 + test_vae_kl + sigma_regularisor\n",
    "    return test_vae_recons_error, test_vae_kl, test_vae_elbo\n",
    "\n",
    "\n",
    "def evaluate_lstm_anomaly_metric_for_a_seq(test_seq):\n",
    "    seq_tensor = torch.from_numpy(test_seq).float().to(device)\n",
    "    seq_tensor = seq_tensor.view(config['l_seq'], config['l_win'], config['n_channel'])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        vae_mean, _ = vae_model.encode(seq_tensor)\n",
    "        input_embeddings = vae_mean[:-1].unsqueeze(0)\n",
    "        lstm_pred = lstm_model(input_embeddings).squeeze(0)\n",
    "        embedding_error = torch.sum((vae_mean[1:] - lstm_pred) ** 2).item()\n",
    "\n",
    "        reconstructed = vae_model.decode(lstm_pred)\n",
    "        reconstructed = reconstructed.squeeze(-1)\n",
    "        target_windows = seq_tensor[1:].squeeze(-1)\n",
    "        reconstruction_error = torch.sum((reconstructed - target_windows) ** 2).item()\n",
    "\n",
    "    return reconstruction_error, embedding_error\n",
    "\n",
    "n_val_vae = data.val_set_vae['data'].shape[0]\n",
    "n_val_lstm = data.val_set_lstm['data'].shape[0]\n",
    "\n",
    "val_vae_recons_error = np.zeros(n_val_vae)\n",
    "val_vae_kl_error = np.zeros(n_val_vae)\n",
    "val_vae_elbo_loss = np.zeros(n_val_vae)\n",
    "for i in range(n_val_vae):\n",
    "    val_vae_recons_error[i], val_vae_kl_error[i], val_vae_elbo_loss[i] = evaluate_vae_anomaly_metrics_for_a_window(data.val_set_vae['data'][i])\n",
    "\n",
    "val_lstm_recons_error, val_lstm_embedding_error = np.zeros(n_val_lstm), np.zeros(n_val_lstm)\n",
    "for i in range(n_val_lstm):\n",
    "    val_lstm_recons_error[i], val_lstm_embedding_error[i] = evaluate_lstm_anomaly_metric_for_a_seq(data.val_set_lstm['data'][i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "def plot_histogram(test_anomaly_metric, n_bins, title, mean=None, std=None, xlim=None, saveplot=False):\n",
    "    test_anomaly_list = np.squeeze(np.ndarray.flatten(test_anomaly_metric))\n",
    "    his = plt.hist(test_anomaly_list, bins=n_bins, density=True)\n",
    "    if mean is None and std is None:\n",
    "        mean = np.mean(test_anomaly_list)\n",
    "        std = np.std(test_anomaly_list)\n",
    "        legend_label = None\n",
    "    else:\n",
    "        legend_label = 1\n",
    "    x_axis = np.arange(mean-5*std, mean+5*std, std/100)\n",
    "    plt.plot(x_axis, norm.pdf(x_axis,mean,std))\n",
    "    plt.title(title)\n",
    "    plt.xlabel('anomaly score value')\n",
    "    plt.ylabel('probability density')\n",
    "    if xlim is not None:\n",
    "        plt.xlim(0, xlim)\n",
    "    else:\n",
    "        plt.xlim(0, np.amax(test_anomaly_list))\n",
    "    if legend_label is None:\n",
    "        plt.legend(('Fitted Gaussian', 'histogram'))\n",
    "    else:\n",
    "        plt.legend(('normal data distribution','test data distribution (contain anomalies)'))\n",
    "    if saveplot:\n",
    "        savefig(config['result_dir']+'reconstruction_error_histogram.pdf')\n",
    "    else:\n",
    "        plt.show()\n",
    "    threshold_25 = np.percentile(test_anomaly_list, 25)\n",
    "    threshold_75 = np.percentile(test_anomaly_list, 75)\n",
    "    threshold_1 = np.percentile(test_anomaly_list, 99)\n",
    "    idx_large_error = np.squeeze(np.argwhere(test_anomaly_metric > threshold_1))\n",
    "#     print(his[0][-20:])\n",
    "#     print(his[1][-20:])\n",
    "    print(\"25% percentile: {}\".format(threshold_25))\n",
    "    print(\"75% percentile: {}\".format(threshold_75))\n",
    "#     print(\"Median: {}\".format(np.median(test_anomaly_list)))\n",
    "#     print(\"Mean: {}\".format(np.mean(test_anomaly_list)))\n",
    "#     print(\"Std dev: {}\".format(np.std(test_anomaly_list)))\n",
    "    print(\"These windows scored the top 1% of anomaly metric ({}): \\n{}\".format(threshold_1, idx_large_error))\n",
    "    return mean, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of VAE ELBO loss - validation set\n",
    "vae_elbo_m, vae_elbo_std = plot_histogram(val_vae_elbo_loss, 100, \n",
    "                                          'VAE ELBO error distribution on the val set', \n",
    "                                          mean=None, std=None, xlim=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of LSTM reconstruction error - validation set \n",
    "#  --> to decide the anomaly detection threshold\n",
    "lstm_recons_m, lstm_recons_std = plot_histogram(val_lstm_recons_error, 100,  \n",
    "                                              'LSTM reconstruction error distribution on the val set', \n",
    "                                              mean=None, std=None, xlim=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the anomaly metrics on the test windows and sequences\n",
    "n_test_lstm = test_seq.shape[0]\n",
    "\n",
    "test_lstm_recons_error, test_lstm_embedding_error = np.zeros(n_test_lstm), np.zeros(n_test_lstm)\n",
    "for i in range(n_test_lstm):\n",
    "    test_lstm_recons_error[i], test_lstm_embedding_error[i] = evaluate_lstm_anomaly_metric_for_a_seq(test_seq[i])\n",
    "print(\"All windows' reconstruction error is computed.\")\n",
    "print(\"The total number of windows is {}\".format(len(test_lstm_recons_error)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of LSTM reconstruction error - test set \n",
    "#  --> to detect anomaly now\n",
    "_, _ = plot_histogram(test_lstm_recons_error, 100,\n",
    "                      'LSTM reconstruction error distribution on the test set', \n",
    "                      mean=lstm_recons_m, std=lstm_recons_std, xlim=None, saveplot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce the ground truth anomaly indices \n",
    "# if result['idx_split'][0] == 0:\n",
    "#     idx_anomaly_test = result['idx_anomaly_test']\n",
    "# else:\n",
    "#     idx_anomaly_test = result['idx_anomaly_test'][0]\n",
    "idx_anomaly_test = result['idx_anomaly_test']    \n",
    "anomaly_index_lstm = []\n",
    "test_labels_lstm = np.zeros(n_test_lstm)\n",
    "for i in range(len(idx_anomaly_test)):\n",
    "    idx_start = idx_anomaly_test[i]-(config['l_win']*config['l_seq']-1)\n",
    "    idx_end = idx_anomaly_test[i]+1\n",
    "    if idx_start < 0:\n",
    "        idx_start = 0\n",
    "    if idx_end > n_test_lstm:\n",
    "        idx_end = n_test_lstm\n",
    "    anomaly_index_lstm.append(np.arange(idx_start,idx_end))\n",
    "    test_labels_lstm[idx_start:idx_end] = 1\n",
    "    \n",
    "print(test_labels_lstm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_anomaly_idx_by_threshold(test_anomaly_metric, threshold):\n",
    "    test_list = np.squeeze(np.ndarray.flatten(test_anomaly_metric))\n",
    "    idx_error = np.squeeze(np.argwhere(test_anomaly_metric > threshold))\n",
    "    \n",
    "    if len(idx_error.shape) == 0:\n",
    "        idx_error = np.expand_dims(idx_error, 0)\n",
    "    \n",
    "    return list(idx_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_detected_idx(idx_detected_anomaly, anomaly_index):\n",
    "    n_anomaly = len(anomaly_index)\n",
    "    idx_detected_anomaly_extended = list(idx_detected_anomaly)\n",
    "    for i in range(n_anomaly):\n",
    "        #print(idx_detected_anomaly)\n",
    "        for j in idx_detected_anomaly:\n",
    "            if j in anomaly_index[i]:\n",
    "                in_original_detection = set(idx_detected_anomaly_extended)\n",
    "                currect_anomaly_win = set(anomaly_index[i])\n",
    "                idx_detected_anomaly_extended = idx_detected_anomaly_extended + list(currect_anomaly_win - in_original_detection)\n",
    "                #print(j)\n",
    "                break\n",
    "                \n",
    "    return list(np.sort(idx_detected_anomaly_extended))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_TP_FP_FN(idx_detected_anomaly, anomaly_index, test_labels):\n",
    "    n_TP = 0\n",
    "    n_FP = 0\n",
    "    n_detection = len(idx_detected_anomaly)\n",
    "    for i in range(n_detection):\n",
    "        if test_labels[idx_detected_anomaly[i]] == 1:\n",
    "            n_TP = n_TP + 1\n",
    "        else:\n",
    "            n_FP = n_FP + 1\n",
    "    \n",
    "    idx_undetected = list(set(np.arange(len(test_labels)))- set(idx_detected_anomaly))\n",
    "    n_FN = 0\n",
    "    for i in idx_undetected:\n",
    "        if test_labels[i] == 1:\n",
    "            n_FN = n_FN + 1\n",
    "    \n",
    "    return n_TP, n_FP, n_FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_precision_and_recall(idx_detected_anomaly, anomaly_index, test_labels):\n",
    "    # compute true positive\n",
    "    n_TP, n_FP, n_FN = count_TP_FP_FN(idx_detected_anomaly, anomaly_index, test_labels)\n",
    "    \n",
    "    if n_TP + n_FP == 0:\n",
    "        precision = 1\n",
    "    else:\n",
    "        precision = n_TP / (n_TP + n_FP)\n",
    "    recall = n_TP / (n_TP + n_FN)\n",
    "    if precision + recall == 0:\n",
    "        F1 = 0\n",
    "    else:\n",
    "        F1 = 2* (precision * recall)/(precision + recall)\n",
    "    \n",
    "    return precision, recall, F1, n_TP, n_FP, n_FN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_threshold = 200\n",
    "precision = np.zeros(n_threshold)\n",
    "recall = np.zeros(n_threshold)\n",
    "F1 = np.zeros(n_threshold)\n",
    "precision_aug = np.zeros(n_threshold)\n",
    "recall_aug = np.zeros(n_threshold)\n",
    "F1_aug = np.zeros(n_threshold)\n",
    "i = 0\n",
    "threshold_list = np.linspace(np.amin(test_lstm_recons_error), np.amax(test_lstm_recons_error), n_threshold, endpoint=True)\n",
    "threshold_list = np.flip(threshold_list)\n",
    "for threshold in threshold_list:\n",
    "    #print(threshold_list[i])\n",
    "    idx_detection_lstm = return_anomaly_idx_by_threshold(test_lstm_recons_error, threshold)\n",
    "    precision[i], recall[i], F1[i], _, _, _ = compute_precision_and_recall(idx_detection_lstm, \n",
    "                                                                           anomaly_index_lstm, \n",
    "                                                                           test_labels_lstm)\n",
    "    # augment the detection using the ground truth labels\n",
    "    # a method to discount the factor one anomaly appears in multiple consecutive windows\n",
    "    # introduced in \"Unsupervised anomaly detection via variational auto-encoder for seasonal kpis in web applications\"\n",
    "    idx_detection_lstm_augmented = augment_detected_idx(idx_detection_lstm, anomaly_index_lstm)\n",
    "    precision_aug[i], recall_aug[i], F1_aug[i], _, _, _ = compute_precision_and_recall(idx_detection_lstm_augmented, \n",
    "                                                                                       anomaly_index_lstm, \n",
    "                                                                                       test_labels_lstm)\n",
    "    i = i + 1\n",
    "    #print(precision, recall, F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Best F1 score is {}\".format(np.amax(F1)))\n",
    "idx_best_threshold = np.squeeze(np.argwhere(F1 == np.amax(F1)))\n",
    "print(\"Best threshold is {}\".format(threshold_list[idx_best_threshold]))\n",
    "print(\"At this threshold, precision is {}, recall is {}\".format(precision[idx_best_threshold], recall[idx_best_threshold]))\n",
    "average_precision = np.sum(precision[1:] * (recall[1:] - recall[:-1]))\n",
    "print(\"Average precision is {}\".format(average_precision))\n",
    "\n",
    "print(\"\\nAugmented detection:\")\n",
    "print(\"Best F1 score is {}\".format(np.amax(F1_aug)))\n",
    "idx_best_threshold = np.squeeze(np.argwhere(F1_aug == np.amax(F1_aug)))\n",
    "print(\"Best threshold is {}\".format(threshold_list[idx_best_threshold]))\n",
    "print(\"At this threshold, precision is {}, recall is {}\".format(precision_aug[idx_best_threshold], \n",
    "                                                                recall_aug[idx_best_threshold]))\n",
    "\n",
    "average_precision_aug = np.sum(precision_aug[1:] * (recall_aug[1:] - recall_aug[:-1]))\n",
    "print(\"Average precision is {}\".format(average_precision_aug))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now select a threshold\n",
    "threshold = 4399\n",
    "\n",
    "print(\"Threshold is {}\".format(threshold))\n",
    "idx_detection = return_anomaly_idx_by_threshold(test_lstm_recons_error, threshold)\n",
    "idx_detection_augmented = augment_detected_idx(idx_detection, anomaly_index_lstm)\n",
    "precision, recall, F1, n_TP, n_FP, n_FN = compute_precision_and_recall(idx_detection_augmented, \n",
    "                                                                       anomaly_index_lstm, \n",
    "                                                                       test_labels_lstm)\n",
    "print(\"\\nPR evaluation using augmented detection:\")\n",
    "print(\"Precision: {}\".format(precision))\n",
    "print(\"Recall: {}\".format(recall))\n",
    "print(\"F1: {}\".format(F1))\n",
    "print(\"TP: {}\".format(n_TP))\n",
    "print(\"FP: {}\".format(n_FP))\n",
    "print(\"FN: {}\".format(n_FN))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_detected_indices_into_seq(idx_detection, interval):\n",
    "    detected_seq = []\n",
    "    i = 0\n",
    "    while i < len(idx_detection):\n",
    "        if i == 0:\n",
    "            cur_seq = [idx_detection[i]]\n",
    "            i = i + 1\n",
    "        else:\n",
    "            if idx_detection[i] - idx_detection[i-1] > interval:\n",
    "                detected_seq.append(cur_seq)\n",
    "                cur_seq = [idx_detection[i]]\n",
    "            else:\n",
    "                cur_seq.append(idx_detection[i])\n",
    "                if i == len(idx_detection) - 1:\n",
    "                    detected_seq.append(cur_seq)\n",
    "            i = i + 1\n",
    "    \n",
    "    print(\"Detected {} sequences\".format(len(detected_seq)))\n",
    "    return detected_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_detected_anomalies(idx_detection, interval, dataset, result, detection_method, augmented_flag=1, y_scale=5, y_lim=None):\n",
    "    detected_seq = slice_detected_indices_into_seq(idx_detection, interval=interval)\n",
    "    t_test = result['t_test']\n",
    "    test = result['test']\n",
    "    idx_anomaly_test = result['idx_anomaly_test']\n",
    "        \n",
    "    # plot detected sequences\n",
    "    fig, axs = plt.subplots(1, 1, figsize=(18, 5), edgecolor='k')\n",
    "    fig.subplots_adjust(hspace=.4, wspace=.4)\n",
    "    axs.plot(t_test, test)\n",
    "    for j in range(len(idx_anomaly_test)):\n",
    "        if j == 0:\n",
    "            axs.plot(idx_anomaly_test[j] * np.ones(20), np.linspace(-y_scale, y_scale, 20), 'r--', label='true anomalies')\n",
    "        else:\n",
    "            axs.plot(idx_anomaly_test[j] * np.ones(20), np.linspace(-y_scale, y_scale, 20), 'r--')\n",
    "        \n",
    "    for i in range(len(detected_seq)):\n",
    "        for j in detected_seq[i]:\n",
    "            if j == detected_seq[0][0]:\n",
    "                axs.plot((j+interval*2) * np.ones(20), np.linspace(-y_scale, -0.8*y_scale, 20), 'g-', label='detected anomalies')\n",
    "            else:\n",
    "                axs.plot((j+interval*2) * np.ones(20), np.linspace(-y_scale, -0.8*y_scale, 20), 'g-')\n",
    "    \n",
    "    for j in range(len(idx_anomaly_test)):\n",
    "        axs.plot(idx_anomaly_test[j] * np.ones(20), np.linspace(-y_scale, y_scale, 20), 'r--')\n",
    "\n",
    "    for i in range(len(detected_seq)):\n",
    "        interval_x = np.asarray([detected_seq[i][0], detected_seq[i][-1]+interval*2])\n",
    "        interval_y = np.asarray([y_scale,y_scale])\n",
    "        if i == 0:\n",
    "            axs.fill_between(interval_x, interval_y, alpha=0.2, color='y', label='detected anomaly windows')\n",
    "        else:\n",
    "            axs.fill_between(interval_x, interval_y, alpha=0.2, color='y')\n",
    "        interval_y = np.asarray([-y_scale,-y_scale])\n",
    "        axs.fill_between(interval_x, interval_y, alpha=0.2, color='y')\n",
    "    axs.grid(True)\n",
    "    axs.set_xlim(0, len(t_test))\n",
    "    if y_lim is None:\n",
    "        axs.set_ylim(-y_scale, y_scale)\n",
    "    else:\n",
    "        axs.set_ylim(-y_scale, y_lim)\n",
    "    axs.set_xlabel(\"timestamp (every {})\".format(result['t_unit']))\n",
    "    axs.set_ylabel(\"normalised readings\")\n",
    "    axs.set_title(\"{} dataset test sequence\\n(normalised by train mean {:.4f} and std {:.4f})\\n Detection method: {}\".format(dataset, \n",
    "                                                                                        result['train_m'], \n",
    "                                                                                        result['train_std'],\n",
    "                                                                                        detection_method))\n",
    "    axs.legend()\n",
    "    savefig(config['result_dir']+'detected_anomalies_{}_aug_{}.pdf'.format(detection_method, augmented_flag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_detected_anomalies(idx_detection_augmented, \n",
    "                        interval=config['l_win']*config['l_seq']/2, \n",
    "                        dataset=dataset, \n",
    "                        result=result, \n",
    "                        detection_method='lstm reconstruction error',\n",
    "                        augmented_flag=1,\n",
    "                        y_scale=5,\n",
    "                        y_lim=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
